# Use the CUDA image with version 12.4.1 and cuDNN support as the base image
FROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04

# Set labels
LABEL com.danswer.maintainer="founders@danswer.ai"
LABEL com.danswer.description="This image is for the Danswer model server which runs all of the \
AI models for Danswer. This container and all the code is MIT Licensed and free for all to use. \
You can find it at https://hub.docker.com/r/danswer/danswer-model-server. For more details, \
visit https://github.com/danswer-ai/danswer."


# Default DANSWER_VERSION, typically overriden during builds by GitHub Actions.
ARG DANSWER_VERSION=0.8-dev

ENV DANSWER_VERSION=${DANSWER_VERSION} \
    DANSWER_RUNNING_IN_DOCKER="true"

RUN echo "DANSWER_VERSION: ${DANSWER_VERSION}"

# Install basic dependencies and Python 3.11
#RUN apt-get update && apt-get install -y --no-install-recommends \
#    build-essential \
#    python3 \
#    python3-venv \
#    python3-pip \
#    git \
#    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Create a symlink for python to point to python3.11
#RUN ln -s /usr/bin/python3 /usr/bin/python

# Install basic dependencies and Python 3.11
#RUN apt-get update && apt-get install -y --no-install-recommends \
#    build-essential \
#    python3.11 \
#    python3.11-venv \
#    python3-pip \
#    python3.11-dev \
#    gcc \
#    git \
#    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Install basic dependencies and CUDA development tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    python3.11 \
    python3.11-venv \
    python3-pip \
    python3.11-dev \
    python3.10-dev \
    gcc-11 \
    g++-11 \
    cuda-toolkit-12-1 \
    libcudnn8-dev \
    git \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Set gcc-11 as default
RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 60 && \
    update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 60

# Create a symlink for python to point to python3.11
RUN ln -s /usr/bin/python3 /usr/bin/python

# Copy and install Python requirements for the model server
COPY ./requirements/model_server.txt /tmp/requirements.txt
RUN pip install --no-cache-dir --upgrade --retries 5 --timeout 30 -r /tmp/requirements.txt

# Install PyTorch and other required dependencies for CUDA 12.4
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 17.10  On ajoute XFORMERS
RUN  pip install -U xformers --index-url https://download.pytorch.org/whl/cu124

# Install packaging and ninja
RUN pip install --no-cache-dir packaging ninja

# Verify ninja installation
RUN ninja --version && echo $? || (pip uninstall -y ninja && pip install ninja)

# Install flash-attn
#RUN pip install flash-attn --no-build-isolation

# Install flash-attn with CUDA support
RUN pip install flash-attn --no-build-isolation --extra-index-url https://download.pytorch.org/whl/cu124


# Install transformers, huggingface_hub, and sentence_transformers
RUN pip install transformers huggingface_hub sentence-transformers

# Pre-download models for setups with limited egress
RUN python -c "from transformers import AutoTokenizer; \
AutoTokenizer.from_pretrained('distilbert-base-uncased'); \
AutoTokenizer.from_pretrained('mixedbread-ai/mxbai-rerank-xsmall-v1'); \
from huggingface_hub import snapshot_download; \
snapshot_download(repo_id='danswer/hybrid-intent-token-classifier', revision='v1.0.3'); \
snapshot_download('nomic-ai/nomic-embed-text-v1'); \
snapshot_download('mixedbread-ai/mxbai-rerank-xsmall-v1'); \
from sentence_transformers import SentenceTransformer; \
SentenceTransformer(model_name_or_path='nomic-ai/nomic-embed-text-v1', trust_remote_code=True);"

# In case the user has volumes mounted to /root/.cache/huggingface that they've downloaded while
# running Danswer, don't overwrite it with the built-in cache folder
RUN mv /root/.cache/huggingface /root/.cache/temp_huggingface

WORKDIR /app

# Copy necessary application files to the working directory
COPY ./danswer/utils/logger.py /app/danswer/utils/logger.py
COPY ./danswer/__init__.py /app/danswer/__init__.py
COPY ./shared_configs /app/shared_configs
COPY ./model_server /app/model_server

# Set the Python path to the /app directory
ENV PYTHONPATH=/app

# Start the model server using uvicorn
CMD ["uvicorn", "model_server.main:app", "--host", "0.0.0.0", "--port", "9000"]

